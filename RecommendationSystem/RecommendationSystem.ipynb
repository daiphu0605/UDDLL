{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recomendsystem",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Cài đặt PySpark"
      ],
      "metadata": {
        "id": "Clprim6PqwrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc_M84OjG8V7"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.2.1-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "R-NjF0Fvq_MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdqsr_o1riaw",
        "outputId": "9cf53a76-75ea-4d5f-a7f1-b66b518dde1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=b31e5ce2b6e4c7959042858c1750fdc101956cf751b40853f232547caa258ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "# Creating a SparkSession in Python\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\")\\\n",
        "          .appName(\"StructureAPI\")\\\n",
        "          .config(\"spark.some.config.option\", \"some-value\")\\\n",
        "          .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "giDrZ3AhrLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dữ liệu nhỏ"
      ],
      "metadata": {
        "id": "e7pFp4M9t5-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tải dữ liệu nhỏ"
      ],
      "metadata": {
        "id": "biTouRzxryfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTC13vMer2p4",
        "outputId": "44eaf7a6-4ff6-4f83-c1bc-d663d0120b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-02 08:04:19--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-04-02 08:04:20 (8.21 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXFsSnkTr-ky",
        "outputId": "d4b15d2c-f0af-4e77-def8-a895f990d50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ml-latest-small      sample_data\t\tspark-3.2.1-bin-hadoop3.2.tgz\n",
            "ml-latest-small.zip  spark-3.2.1-bin-hadoop3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nhập file dữ liệu nhỏ"
      ],
      "metadata": {
        "id": "BEjXqZhgsSwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_datasets_path = 'ml-latest-small'"
      ],
      "metadata": {
        "id": "kOyjNMH7szVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_file = os.path.join(small_datasets_path, 'ratings.csv')\n",
        "small_ratings_raw_data = sc.textFile(small_ratings_file) \n",
        "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] \n",
        "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() \n"
      ],
      "metadata": {
        "id": "7aBcqvL1sXb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(small_ratings_data.take(10))"
      ],
      "metadata": {
        "id": "x3Q2kMtC9Ju5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166ace38-a466-4ebe-a2c7-86b5efdf614d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0'), ('1', '47', '5.0'), ('1', '50', '5.0'), ('1', '70', '3.0'), ('1', '101', '5.0'), ('1', '110', '4.0'), ('1', '151', '5.0'), ('1', '157', '5.0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Số liệu cho mô hình ALS"
      ],
      "metadata": {
        "id": "CbJkYvwjuD4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chia nhỏ tập dữ liệu"
      ],
      "metadata": {
        "id": "0td6gmRmvXh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
        "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1])) \n",
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
      ],
      "metadata": {
        "id": "GyB6Sj6muIm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Thông số cho ALS train"
      ],
      "metadata": {
        "id": "VLXsZuSPv4Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "\n",
        "seed = 5\n",
        "iterations = 10\n",
        "regularization_parameter = 0.1\n",
        "#ranks = [4, 8, 12]\n",
        "#errors = [0, 0, 0]\n",
        "#err = 0\n",
        "#tolerance = 0.02"
      ],
      "metadata": {
        "id": "ndRkZz96vgmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Thực hiện train"
      ],
      "metadata": {
        "id": "q-kq1OhBwpyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_test = ALS.train(training_RDD, rank=8, seed=seed, iterations=iterations,\n",
        "                      lambda_=regularization_parameter)\n",
        "predictions = model_test.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)"
      ],
      "metadata": {
        "id": "QaYc_xrrwtxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RMSE metric"
      ],
      "metadata": {
        "id": "0FWSuPym04hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_RMSE = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print('For testing data the RMSE is %s' % (result_RMSE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs0i0ZR004OU",
        "outputId": "ed13d297-4a4b-484c-9e63-2b7ad41c0b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the RMSE is 0.9100699365514616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hit rate metric"
      ],
      "metadata": {
        "id": "a44mV0Rd1iaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "d7crUfKd1k6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lọc top N\n",
        "#Mặc định top 10 với mức rating là 3\n",
        "def GetTopN(predictions, n=10, minimumRating=3.0):\n",
        "  topN = defaultdict(list)\n",
        "  for userID, movieID, actualRating, estimatedRating in predictions:\n",
        "    if (estimatedRating >= minimumRating):\n",
        "      topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "  for userID, ratings in topN.items():\n",
        "      ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "      topN[int(userID)] = ratings[:n]\n",
        "  return topN"
      ],
      "metadata": {
        "id": "4xQaBHz818o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HitRate(topNPredicted, leftOutPredictions):\n",
        "  hits = 0\n",
        "  total = 0\n",
        "  # For each left-out rating\n",
        "  for leftOut in leftOutPredictions:\n",
        "      userID = leftOut[0]\n",
        "      leftOutMovieID = leftOut[1]\n",
        "      # Is it in the predicted top 10 for this user?\n",
        "      hit = False\n",
        "      for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "        if (int(leftOutMovieID) == int(movieID)):\n",
        "          hit = True\n",
        "          break\n",
        "      if (hit) :\n",
        "        hits += 1\n",
        "      total += 1\n",
        "  # Compute overall precision\n",
        "  return hits/total"
      ],
      "metadata": {
        "id": "1rKe0XMY2Hbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for i in np.array(rates_and_preds.collect()):\n",
        "  preds.append(np.array(i).flatten())\n",
        "tests = test_for_predict_RDD.map(lambda x: (int(x[0]), int(x[1])))\n",
        "\n",
        "result_HitRate = HitRate(GetTopN(preds), np.array(tests.collect()))\n",
        "\n",
        "print('For testing data the HR is %s' % (result_HitRate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN5OxcJD2b3a",
        "outputId": "d9878bbe-ceba-4893-fe24-40f3e0e1bbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the HR is 0.23046181172291297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NDCG metric\n"
      ],
      "metadata": {
        "id": "Xv_CdJMa1iUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NDCG(rel_true, rel_pred, p=0, form=\"linear\"):\n",
        "    rel_true = np.sort(rel_true)[::-1]\n",
        "    p = min(len(rel_true), min(len(rel_pred), p))\n",
        "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
        "\n",
        "    if form == \"linear\":\n",
        "        idcg = np.sum(rel_true[:p] * discount)\n",
        "        dcg = np.sum(rel_pred[:p] * discount)\n",
        "    elif form == \"exponential\" or form == \"exp\":\n",
        "        idcg = np.sum([2**x - 1 for x in rel_true[:p]] * discount)\n",
        "        dcg = np.sum([2**x - 1 for x in rel_pred[:p]] * discount)\n",
        "    else:\n",
        "        raise ValueError(\"Only supported for two formula, 'linear' or 'exp'\")\n",
        "\n",
        "    return dcg / idcg"
      ],
      "metadata": {
        "id": "uZkwpsWxKM5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_true = rates_and_preds.map(lambda x: x[1][0])\n",
        "rating_pred = rates_and_preds.map(lambda x: x[1][1])\n",
        "result_NDCG = NDCG(rating_true.collect(), rating_pred.collect(), 4)\n",
        "\n",
        "print('For testing data the HR is %s' % (result_NDCG))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh_a8Pb-28kc",
        "outputId": "8e63633d-90aa-406a-d193-f87d5a90d84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the HR is 0.8291152648363814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dữ liệu lớn"
      ],
      "metadata": {
        "id": "_S1tU4RT38fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tải dữ liệu lớn"
      ],
      "metadata": {
        "id": "yRfsCD3qeVXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5f4Dwmt4E7R",
        "outputId": "2b8b3ed7-b658-4f0f-993c-bfb00d142a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-02 08:13:59--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  33.1MB/s    in 0.2s    \n",
            "\n",
            "2022-04-02 08:13:59 (33.1 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n",
            "ml-1m\t\t ml-latest-small.zip\t    spark-3.2.1-bin-hadoop3.2.tgz\n",
            "ml-1m.zip\t sample_data\n",
            "ml-latest-small  spark-3.2.1-bin-hadoop3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nhập dữ liệu lớn"
      ],
      "metadata": {
        "id": "G4E-DplA6p-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "big_datasets_path = 'ml-1m'\n",
        "big_ratings_file = os.path.join(big_datasets_path, 'ratings.dat')\n",
        "big_ratings_raw_data = sc.textFile(big_ratings_file) \n",
        "#big_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] \n",
        "#big_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() \n",
        "big_ratings_data = big_ratings_raw_data.map(lambda line: line.split(\"::\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() \n"
      ],
      "metadata": {
        "id": "33xt8y5z6tJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_ratings_data.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tixC1SRM624F",
        "outputId": "4b0157e4-6f54-48e3-d7fc-b2a4ad1828c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '1193', '5'),\n",
              " ('1', '661', '3'),\n",
              " ('1', '914', '3'),\n",
              " ('1', '3408', '4'),\n",
              " ('1', '2355', '5'),\n",
              " ('1', '1197', '3'),\n",
              " ('1', '1287', '5'),\n",
              " ('1', '2804', '5'),\n",
              " ('1', '594', '4'),\n",
              " ('1', '919', '4')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nhập số liệu ALS"
      ],
      "metadata": {
        "id": "4dtEKhq79Qti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chia nhỏ tập dữ liệu"
      ],
      "metadata": {
        "id": "76Z5NRVG9zeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_bRDD, test_bRDD = big_ratings_data.randomSplit([6,4], seed=0)\n",
        "test_for_predict_bRDD = test_bRDD.map(lambda x: (x[0], x[1]))"
      ],
      "metadata": {
        "id": "-CobyGHm9XK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Thông số train ALS train"
      ],
      "metadata": {
        "id": "dZ_Oj51C-AwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "\n",
        "seed = 5\n",
        "iterations = 10\n",
        "regularization_parameter = 0.1\n",
        "#ranks = [4, 8, 12]\n",
        "#errors = [0, 0, 0]\n",
        "#err = 0\n",
        "#tolerance = 0.02"
      ],
      "metadata": {
        "id": "_q2m4STA-MXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Thực hiện train"
      ],
      "metadata": {
        "id": "QBT6bDV5-ZzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bmodel_test = ALS.train(training_bRDD, rank=4, seed=seed, iterations=iterations,\n",
        "                      lambda_=regularization_parameter)\n",
        "predictions = big_ratings_data.predictAll(test_for_predict_bRDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_bRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)"
      ],
      "metadata": {
        "id": "yMPsgobO-b7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RMSE metrix"
      ],
      "metadata": {
        "id": "trLI5qONe3Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_RMSE = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print('For testing data the RMSE is %s' % (result_RMSE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF4-A7DVe6iW",
        "outputId": "545bb8d1-6229-4a5f-8fe9-9f0fd4590a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the RMSE is 0.9301901571026362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hit rate metric"
      ],
      "metadata": {
        "id": "9xjKxG79fWpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5aonP4HufWpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lọc top N\n",
        "#Mặc định top 10 với mức rating là 3\n",
        "def GetTopN(predictions, n=10, minimumRating=3.0):\n",
        "  topN = defaultdict(list)\n",
        "  for userID, movieID, actualRating, estimatedRating in predictions:\n",
        "    if (estimatedRating >= minimumRating):\n",
        "      topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "  for userID, ratings in topN.items():\n",
        "      ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "      topN[int(userID)] = ratings[:n]\n",
        "  return topN"
      ],
      "metadata": {
        "id": "o79wRNdwfWpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HitRate(topNPredicted, leftOutPredictions):\n",
        "  hits = 0\n",
        "  total = 0\n",
        "  # For each left-out rating\n",
        "  for leftOut in leftOutPredictions:\n",
        "      userID = leftOut[0]\n",
        "      leftOutMovieID = leftOut[1]\n",
        "      # Is it in the predicted top 10 for this user?\n",
        "      hit = False\n",
        "      for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "        if (int(leftOutMovieID) == int(movieID)):\n",
        "          hit = True\n",
        "          break\n",
        "      if (hit) :\n",
        "        hits += 1\n",
        "      total += 1\n",
        "  # Compute overall precision\n",
        "  return hits/total"
      ],
      "metadata": {
        "id": "f1_JwLRtfWpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for i in np.array(rates_and_preds.collect()):\n",
        "  preds.append(np.array(i).flatten())\n",
        "tests = test_for_predict_bRDD.map(lambda x: (int(x[0]), int(x[1])))\n",
        "\n",
        "result_HitRate = HitRate(GetTopN(preds), np.array(tests.collect()))\n",
        "\n",
        "print('For testing data the HR is %s' % (result_HitRate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6307efc6-a210-4ff4-c746-ee6321c6530a",
        "id": "tMb-iVVWfWp0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the HR is 0.23046181172291297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NDCG metric\n"
      ],
      "metadata": {
        "id": "Rx65wnH7ftqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NDCG(rel_true, rel_pred, p=0, form=\"linear\"):\n",
        "    rel_true = np.sort(rel_true)[::-1]\n",
        "    p = min(len(rel_true), min(len(rel_pred), p))\n",
        "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
        "\n",
        "    if form == \"linear\":\n",
        "        idcg = np.sum(rel_true[:p] * discount)\n",
        "        dcg = np.sum(rel_pred[:p] * discount)\n",
        "    elif form == \"exponential\" or form == \"exp\":\n",
        "        idcg = np.sum([2**x - 1 for x in rel_true[:p]] * discount)\n",
        "        dcg = np.sum([2**x - 1 for x in rel_pred[:p]] * discount)\n",
        "    else:\n",
        "        raise ValueError(\"Only supported for two formula, 'linear' or 'exp'\")\n",
        "\n",
        "    return dcg / idcg"
      ],
      "metadata": {
        "id": "tyy7Gy9tftq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_true = rates_and_preds.map(lambda x: x[1][0])\n",
        "rating_pred = rates_and_preds.map(lambda x: x[1][1])\n",
        "result_NDCG = NDCG(rating_true.collect(), rating_pred.collect(), 4)\n",
        "\n",
        "print('For testing data the HR is %s' % (result_NDCG))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f55903-e96e-42ae-fea7-09ee5703bf01",
        "id": "A7Osa2bAftq6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the HR is 0.8291152648363814\n"
          ]
        }
      ]
    }
  ]
}